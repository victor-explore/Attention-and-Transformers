# Attention and Transformers

A curated list of the best resources to learn about Attention Mechanisms and Transformer architectures.

## Papers
- [Attention Is All You Need](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) - Original paper introducing the Transformer architecture by Vaswani et al. (2017)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) - Landmark paper by Google Research introducing BERT (2018)

## Blog Posts
- [The Transformer Family](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/) - Comprehensive overview of Transformer variants by Lilian Weng
- [The Illustrated Transformer](https://lilianweng.github.io/posts/2018-06-24-attention/) - Visual guide to Transformers by Jay Alammar
- [Attention? Attention!](https://jalammar.github.io/illustrated-transformer/) - Deep dive into attention mechanisms by Lilian Weng

## Videos
- [How I Understand Transformers](https://www.youtube.com/watch?v=rcWMRA9E5RI) - Intuitive explanation by Jia-Bin Huang
